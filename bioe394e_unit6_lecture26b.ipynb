{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from torchtext import data, datasets\n",
    "import numpy as np\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "SEED = 1234\n",
    "TRAIN = False\n",
    "BATCH_SIZE = 128\n",
    "N_EPOCHS = 1\n",
    "\n",
    "# Architecture\n",
    "HIDDEN_DIM = 256\n",
    "OUTPUT_DIM = 1\n",
    "N_LAYERS = 2\n",
    "BIDIRECTIONAL = True\n",
    "DROPOUT = 0.25\n",
    "\n",
    "TEXT = \"I hate you!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get tokens for BERT\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "init_token_id = tokenizer.cls_token_id\n",
    "eos_token_id  = tokenizer.sep_token_id\n",
    "pad_token_id  = tokenizer.pad_token_id\n",
    "unk_token_id  = tokenizer.unk_token_id\n",
    "\n",
    "max_input_len = tokenizer.max_model_input_sizes['bert-base-uncased']\n",
    "\n",
    "# Tokensize and crop sentence to 510 (for 1st and last token) instead of 512 (i.e. `max_input_len`)\n",
    "def tokenize_and_crop(sentence):\n",
    "  tokens = tokenizer.tokenize(sentence)\n",
    "  tokens = tokens[:max_input_len - 2]\n",
    "  return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "  text = data.Field(\n",
    "    batch_first=True,\n",
    "    use_vocab=False,\n",
    "    tokenize=tokenize_and_crop,\n",
    "    preprocessing=tokenizer.convert_tokens_to_ids,\n",
    "    init_token=init_token_id,\n",
    "    pad_token=pad_token_id,\n",
    "    unk_token=unk_token_id\n",
    "  )\n",
    "\n",
    "label = data.LabelField(dtype=torch.float)\n",
    "\n",
    "train_data, test_data  = datasets.IMDB.splits(text, label)\n",
    "train_data, valid_data = train_data.split(random_state=random.seed(SEED))\n",
    "\n",
    "print(f\"training examples count: {len(train_data)}\")\n",
    "print(f\"test examples count: {len(test_data)}\")\n",
    "print(f\"validation examples count: {len(valid_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "  text = data.Field(\n",
    "    batch_first=True,\n",
    "    use_vocab=False,\n",
    "    tokenize=tokenize_and_crop,\n",
    "    preprocessing=tokenizer.convert_tokens_to_ids,\n",
    "    init_token=init_token_id,\n",
    "    pad_token=pad_token_id,\n",
    "    unk_token=unk_token_id\n",
    "  )\n",
    "\n",
    "  label = data.LabelField(dtype=torch.float)\n",
    "\n",
    "  train_data, test_data  = datasets.IMDB.splits(text, label)\n",
    "  train_data, valid_data = train_data.split(random_state=random.seed(SEED))\n",
    "\n",
    "  print(f\"training examples count: {len(train_data)}\")\n",
    "  print(f\"test examples count: {len(test_data)}\")\n",
    "  print(f\"validation examples count: {len(valid_data)}\")\n",
    "\n",
    "  label.build_vocab(train_data)\n",
    "\n",
    "  train_iter, valid_iter, test_iter = data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    device=device\n",
    "  )\n",
    "\n",
    "  return train_iter, valid_iter, test_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentModel(nn.Module):\n",
    "  def __init__(\n",
    "    self,\n",
    "    bert,\n",
    "    hidden_dim,\n",
    "    output_dim,\n",
    "    n_layers,\n",
    "    bidirectional,\n",
    "    dropout\n",
    "  ):\n",
    "      \n",
    "    super(SentimentModel, self).__init__()\n",
    "    \n",
    "    self.bert = bert\n",
    "    embedding_dim = bert.config.to_dict()['hidden_size']\n",
    "    self.rnn = nn.GRU(\n",
    "      embedding_dim,\n",
    "      hidden_dim,\n",
    "      num_layers=n_layers,\n",
    "      bidirectional=bidirectional,\n",
    "      batch_first=True,\n",
    "      dropout=0 if n_layers < 2 else dropout\n",
    "    )\n",
    "    self.out = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)\n",
    "    self.dropout = nn.Dropout(dropout)\n",
    "      \n",
    "  def forward(self, text):\n",
    "    with torch.no_grad():\n",
    "      embedded = self.bert(text)[0]\n",
    "            \n",
    "    _, hidden = self.rnn(embedded)\n",
    "    \n",
    "    if self.rnn.bidirectional:\n",
    "      hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
    "    else:\n",
    "      hidden = self.dropout(hidden[-1,:,:])\n",
    "    \n",
    "    output = self.out(hidden)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentimentModel(\n",
    "  bert_model,\n",
    "  HIDDEN_DIM,\n",
    "  OUTPUT_DIM,\n",
    "  N_LAYERS,\n",
    "  BIDIRECTIONAL,\n",
    "  DROPOUT\n",
    ")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "  elapsed_time = end_time - start_time\n",
    "  elapsed_mins = int(elapsed_time / 60)\n",
    "  elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "  return elapsed_mins, elapsed_secs\n",
    "\n",
    "def binary_accuracy(preds, y):\n",
    "  rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "  correct = (rounded_preds == y).float()\n",
    "  acc = correct.sum() / len(correct)\n",
    "  return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "  # stats\n",
    "  epoch_loss = 0\n",
    "  epoch_acc = 0\n",
    "  # train mode\n",
    "  model.train()\n",
    "  \n",
    "  for batch in iterator:\n",
    "    # train step\n",
    "    optimizer.zero_grad()\n",
    "    predictions = model(batch.text).squeeze(1)\n",
    "    loss = criterion(predictions, batch.label)\n",
    "    acc = binary_accuracy(predictions, batch.label)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    # stats\n",
    "    epoch_loss += loss.item()\n",
    "    epoch_acc += acc.item()\n",
    "  \n",
    "  return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "\n",
    "# evaluates the model on given iterator (either \n",
    "# train_iter, valid_iter, or test_iter)\n",
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "  epoch_loss = 0\n",
    "  epoch_acc = 0\n",
    "  # evaluation mode\n",
    "  model.eval()\n",
    "  \n",
    "  with torch.no_grad():\n",
    "    for batch in iterator:\n",
    "      predictions = model(batch.text).squeeze(1)\n",
    "      loss = criterion(predictions, batch.label)\n",
    "      acc = binary_accuracy(predictions, batch.label)\n",
    "      epoch_loss += loss.item()\n",
    "      epoch_acc += acc.item()\n",
    "      \n",
    "  return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "\n",
    "# function to make sentiment prediction during inference\n",
    "def predict_sentiment(model, tokenizer, sentence):\n",
    "  model.eval()\n",
    "  tokens = tokenizer.tokenize(sentence)\n",
    "  tokens = tokens[:max_input_len - 2]\n",
    "  indexed = [init_token_id] + tokenizer.convert_tokens_to_ids(tokens) + [eos_token_id]\n",
    "  tensor = torch.LongTensor(indexed).to(device)\n",
    "  tensor = tensor.unsqueeze(0)\n",
    "  prediction = torch.sigmoid(model(tensor))\n",
    "  return prediction.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter, valid_iter, test_iter = load_data()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.BCEWithLogitsLoss().to(device)\n",
    "model = model.to(device)\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    # start time\n",
    "    start_time = time.time()\n",
    "    # train for an epoch\n",
    "    train_loss, train_acc = train(model, train_iter, optimizer, criterion)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iter, criterion)\n",
    "    # end time\n",
    "    end_time = time.time()\n",
    "    # stats\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    # save model if has validation loss\n",
    "    # better than last one\n",
    "    if valid_loss < best_valid_loss:\n",
    "      best_valid_loss = valid_loss\n",
    "      torch.save(model.state_dict(), 'model.pt')\n",
    "    \n",
    "    # stats\n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n",
    "# Test\n",
    "model.load_state_dict(torch.load('model.pt'))\n",
    "test_loss, test_acc = evaluate(model, test_iter, criterion)\n",
    "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bioe394e",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
